{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News Posts' Review\n",
    "In this project we'll analyse data of user posts on popular tech platform **Hacker News**. Hacker News is a site started by the startup Y Combinator where user submit stories which are then read by, commented upon, and upvoted/downvoted by the community. It serves a medium for sharing news, developments, and personal experiences relating to tech with similar-minded people on internet.\n",
    "\n",
    "The data we're going to look at comes from a much larger dataset containing around 300,000 rows. But for simplicity, we've removed those entries that did not receive any comments and randomly sampled from the rest. Our dataset has thus been distilled to 20,000 entries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns & What they mean\n",
    "\n",
    "Here's a brief description of columns in our dataset.\n",
    "\n",
    "| title | description |\n",
    "|-----------|------------|\n",
    "|id | A unique numeric value assigned by HN to each post|\n",
    "|title| the title of the post|\n",
    "|url| the url post links to, if any| \n",
    "|num_points|the number of points the post received|\n",
    "|num_comments|the number of comments made on the post|\n",
    "|author| the username of the poster|\n",
    "|created_at| the date & time of post's creation|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "opened_file = open(\"hacker_news.csv\")\n",
    "read_file = reader(opened_file)\n",
    "hn_org = list(read_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length & the first five rows of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of entries in our dataset: 20101 \n",
      "\n",
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n"
     ]
    }
   ],
   "source": [
    "print('no. of entries in our dataset:', len(hn_org), '\\n')\n",
    "\n",
    "for post in hn_org[:5]:\n",
    "    print(post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, since our dataset's first entry comprises column headers, we'll store it in a new variable __headers__ and save the rest of dataset in a new variable __hn__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = hn_org[0]\n",
    "hn = hn_org[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the first five rows of **hn** to verify we've successfully removed the header. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperating Ask HN & Show HN entries\n",
    "Now, after having sorted our data for analysis, we'll move on to performing core operations. The first is to seperate entries with titles strting with Ask HN or Show HN (irrespective of their capitalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of ask posts: 1744 \n",
      "no. of show posts: 1162 \n",
      "no. of other posts: 17194\n",
      "\n",
      " total posts: 20100\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for post in hn:\n",
    "    title = post[1]\n",
    "    \n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(post)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(post)\n",
    "    else:\n",
    "        other_posts.append(post)\n",
    "        \n",
    "print('no. of ask posts:',len(ask_posts), '\\n'\n",
    "      'no. of show posts:',len(show_posts), '\\n'\n",
    "      'no. of other posts:',len(other_posts))\n",
    "print('\\n','total posts:', len(ask_posts) + len(show_posts) + len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating avg comment score:\n",
    "Now we'll write a piece of code to calculate average number of comments for each of the __ask hn__, __show hn__, & __others__ posts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_comments(dataset):\n",
    "    \n",
    "    total = 0\n",
    "    \n",
    "    for index, entry in enumerate(dataset):\n",
    "        comments = int(entry[4])\n",
    "        total += comments\n",
    "        index = index + 1\n",
    "        \n",
    "    avg = round(total / index, 2)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg no. of ask comments: 14.04\n",
      "avg no. of show comments: 10.32\n",
      "avg no. of other comments: 26.87\n"
     ]
    }
   ],
   "source": [
    "avg_ask_comments = avg_comments(ask_posts)\n",
    "print('avg no. of ask comments:', avg_ask_comments)\n",
    "\n",
    "avg_show_comments = avg_comments(show_posts)\n",
    "print('avg no. of show comments:', avg_show_comments)\n",
    "\n",
    "avg_other_comments = avg_comments(other_posts)\n",
    "print('avg no. of other comments:', avg_other_comments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears from calculating average number of comments for ask and show posts that, \n",
    "\n",
    "- ask posts receive more comments than show posts.\n",
    "- posts other than ask or show receive the highest comments on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-wise analysis of posts & comments\n",
    "Since ask posts have the highest number of comments on average, we'll focus solely on them. Moving on, we'll try to see which time segments are likely to yield the highest no. of comments and posts in a day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for post in ask_posts:\n",
    "    created_at = post[6]\n",
    "    comments = int(post[4])\n",
    "    temp_list = [created_at, comments]\n",
    "    result_list.append(temp_list)\n",
    "\n",
    "\n",
    "counts_by_hour, comments_by_hour = {}, {}\n",
    "\n",
    "for entry in result_list:\n",
    "    dt = entry[0]\n",
    "    comments = entry[1]\n",
    "    dt_object = datetime.strptime(dt, \"%m/%d/%Y %H:%M\")\n",
    "    hour = dt_object.strftime(\"%H\")\n",
    "    \n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comments\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comments\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'11': 58, '12': 73, '10': 59, '13': 85, '08': 48, '21': 109, '04': 47, '22': 71, '20': 80, '09': 45, '05': 46, '07': 34, '19': 110, '00': 55, '02': 58, '06': 44, '15': 116, '23': 68, '14': 107, '03': 54, '01': 60, '16': 108, '17': 100, '18': 109}\n",
      "{'11': 641, '12': 687, '10': 793, '13': 1253, '08': 492, '21': 1745, '04': 337, '22': 479, '20': 1722, '09': 251, '05': 464, '07': 267, '19': 1188, '00': 447, '02': 1381, '06': 397, '15': 4477, '23': 543, '14': 1416, '03': 421, '01': 683, '16': 1814, '17': 1146, '18': 1439}\n"
     ]
    }
   ],
   "source": [
    "print(counts_by_hour)\n",
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['11', 11.051724137931034], ['12', 9.41095890410959], ['10', 13.440677966101696], ['13', 14.741176470588234], ['08', 10.25], ['21', 16.009174311926607], ['04', 7.170212765957447], ['22', 6.746478873239437], ['20', 21.525], ['09', 5.5777777777777775], ['05', 10.08695652173913], ['07', 7.852941176470588], ['19', 10.8], ['00', 8.127272727272727], ['02', 23.810344827586206], ['06', 9.022727272727273], ['15', 38.5948275862069], ['23', 7.985294117647059], ['14', 13.233644859813085], ['03', 7.796296296296297], ['01', 11.383333333333333], ['16', 16.796296296296298], ['17', 11.46], ['18', 13.20183486238532]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "comments_list = []\n",
    "posts_list = []\n",
    "\n",
    "for key in counts_by_hour:\n",
    "    for element in comments_by_hour:\n",
    "        if element == key:\n",
    "            avg = comments_by_hour[element] / counts_by_hour[key]\n",
    "            a_list = [element, avg]\n",
    "            avg_by_hour.append(a_list)\n",
    "\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have time-wise average comments per post from our __hn__ dataset. \n",
    "\n",
    "However, in order to make this data more readable, we'll sort the elements of this list in ascending order of their average comment values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['11', 11.051724137931034], ['12', 9.41095890410959], ['10', 13.440677966101696], ['13', 14.741176470588234]]\n"
     ]
    }
   ],
   "source": [
    "print(avg_by_hour[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for list in avg_by_hour:\n",
    "    small_list = [list[1], list[0]]\n",
    "    swap_avg_by_hour.append(small_list)\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "\n",
    "def top_5(list):\n",
    "    print('Top 5 Hours for Ask Post Comments: ')\n",
    "    for list in sorted_swap[:5]:\n",
    "        dt_object = datetime.strptime(list[1], \"%H\")\n",
    "        dt_string = dt_object.strftime(\"%H:%M\")\n",
    "        print(\"{}: {:.2f} average comments per post.\".format(dt_string, list[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the top time slots for highest comments' likelyhood are 15:00, 12:00,...\n",
    "But we're not sure what timezone these figures were recorded in. So, to find out, we've consulted the dataset's documentation availble at kaggle (https://www.kaggle.com/hacker-news/hacker-news-posts). From this description, we've learned that the time zone is US Eastern. \n",
    "\n",
    "But since our point of reference for this analysis is Pakistan, we'll convert these values to PST (Pakistan Standard Time).\n",
    "\n",
    "__Pakistan Standard Time = Eastern Time + 9 Hours__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21']]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_swap[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta, time, datetime\n",
    "\n",
    "for row in sorted_swap:\n",
    "    string_time = row[1]\n",
    "    dt_object = datetime.strptime(string_time, \"%H\")\n",
    "    corrected_time = dt_object + timedelta(hours=9)\n",
    "    corrected_time = corrected_time.strftime(\"%H\")\n",
    "    row[1] = corrected_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38.5948275862069, '00'], [23.810344827586206, '11'], [21.525, '05'], [16.796296296296298, '01'], [16.009174311926607, '06']]\n"
     ]
    }
   ],
   "source": [
    "print(sorted_swap[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top hours w/ highest avg Comments for Pak\n",
    "We can call upon our __top_5(list)__ function to list the hours (in Pakistan Standard Time) that generate the most comments on average when posts are created in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Post Comments: \n",
      "00:00: 38.59 average comments per post.\n",
      "11:00: 23.81 average comments per post.\n",
      "05:00: 21.52 average comments per post.\n",
      "01:00: 16.80 average comments per post.\n",
      "06:00: 16.01 average comments per post.\n"
     ]
    }
   ],
   "source": [
    "top_5(sorted_swap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The findings from this basic analysis tell us that if someone living in Pakistan Standard Time Zone wants to maximize the visibility & user engagement over his posts, he or she should,\n",
    "\n",
    "1. start them with _ask_ rather them _show_ keyword.\n",
    "\n",
    "2. make them just after midnight, at 11 in the morning, 5 in the afternoon, 1 in the afternoon, or 6 in the morning - in that order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
